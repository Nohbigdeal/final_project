{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[\"https://search.shopping.naver.com/catalog/24392669525?query=%EC%95%A0%ED%94%8C&NaPm=ct%3Dkshvs4so%7Cci%3D0505c87579639211eb2f561d61dcc6eb4a959cfd%7Ctr%3Dslsl%7Csn%3D95694%7Chk%3Dda0db7d2c32af0007ed265c466220022f6b20d1f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[3]/a\n",
      "/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[4]/a\n",
      "/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[5]/a\n",
      "/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[6]/a\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    \n",
    "    shoppingmall_review = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[1]/ul/li[4]/a\"\n",
    "\n",
    "    shppingmall_review2 = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[2]/div/div[2]/ul/li[4]/a\"\n",
    "#                                                                v                                ^\n",
    "    point5 = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[2]/a\"\n",
    "    point4 = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[3]/a\"\n",
    "    point3 = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[4]/a\"\n",
    "    point2 = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[5]/a\"\n",
    "    point1 = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[2]/div[2]/ul/li[6]/a\"\n",
    "    points_path = [point4, point3, point2, point1]\n",
    "\n",
    "    title_path = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/ul/li[1]/div[2]/div[1]/em\"\n",
    "    text_path = \"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/ul/li[1]/div[2]/div[1]/p\"\n",
    "\n",
    "    header = {'User-Agent': ''}\n",
    "    d = webdriver.Chrome('chromedriver.exe') # webdriver = chrome\n",
    "    d.implicitly_wait(3)\n",
    "    d.get(url)\n",
    "    req = requests.get(url)\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    a = d.find_element_by_xpath(\"/html/body/div/div/div[2]/div[2]/div[1]/h2\")\n",
    "    a = a.text #상품 제목\n",
    "\n",
    "\n",
    "    elem = d.find_element_by_tag_name(\"body\")\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    sleep(2)\n",
    "\n",
    "    d.find_element_by_xpath(shoppingmall_review).click()\n",
    "    sleep(2)\n",
    "\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    sleep(2)\n",
    "\n",
    "    full_list = [[],[]]\n",
    "\n",
    "\n",
    "    for i in range(len(points_path)):\n",
    "        point = []\n",
    "    \n",
    "        d.find_element_by_xpath(shppingmall_review2).click()\n",
    "        sleep(2)\n",
    "\n",
    "    \n",
    "        d.find_element_by_xpath(points_path[i]).click()\n",
    "        print(points_path[i])\n",
    "        sleep(2)\n",
    "    \n",
    "        page = 1\n",
    "        starpoint = 4-i\n",
    "    \n",
    "        while True:\n",
    "            html = d.page_source\n",
    "            dom = BeautifulSoup(html, \"lxml\")\n",
    "            titles_raw = dom.find_all(\"em\", {\"class\":\"reviewItems_title__39Z8H\"})\n",
    "            texts_raw = dom.find_all(\"p\", {\"class\":\"reviewItems_text__XIsTc\"})\n",
    "\n",
    "\n",
    "            try:\n",
    "                d.find_element_by_xpath(\"/html/body/div/div/div[2]/div[2]/div[2]/div[3]/div[6]/div[3]/a[\"+str(page)+\"]\").click()\n",
    "\n",
    "                sleep(1)\n",
    "                if page == 11:\n",
    "                    page = 2\n",
    "\n",
    "\n",
    "                html = d.page_source\n",
    "                dom = BeautifulSoup(html, \"lxml\")\n",
    "                titles_raw = dom.find_all(\"em\", {\"class\":\"reviewItems_title__39Z8H\"})\n",
    "                texts_raw = dom.find_all(\"p\", {\"class\":\"reviewItems_text__XIsTc\"})\n",
    "            \n",
    "            \n",
    "                for text_raw in texts_raw:\n",
    "                    full_list[0].append(text_raw.text)\n",
    "                    full_list[1].append(starpoint)\n",
    "                    point.append(starpoint)\n",
    "\n",
    "                if len(texts_raw) != 20:\n",
    "                    break\n",
    "        \n",
    "                page = page + 1\n",
    "            \n",
    "                if len(point) > 400:\n",
    "                    break\n",
    "            \n",
    "                sleep(4)\n",
    "            except:\n",
    "                for text_raw in texts_raw:\n",
    "                    full_list[0].append(text_raw.text)\n",
    "                    full_list[1].append(starpoint)\n",
    "                    point.append(starpoint)\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    d.quit()\n",
    "            \n",
    "    df = pd.DataFrame(full_list)\n",
    "    df = df.T\n",
    "    df.columns = [\"review\", \"star\"]\n",
    "    df.to_csv(\"C:/690009/TP2/final_project/member/NTJ/crawlerNSstar/data/\"+a+\".csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4일만에 도착!!! 폭설로 택배사에서 하루 주무심!그레이 생각보다 괜찮네요!뭐 작동...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>상품은 안전하게 잘 와서 너무 만족합니다. 하자도 없고 원하던 색상으로 잘 왔어요~...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>배송 빠른건 정말 너무 만족했어요!하지만 배송 과정 중의 문제인지는 모르겠지만 아이...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>해외서 오는 시간이 있어 배송이 조금 아쉬웠지만 만족합니다. 문구에 적어 주셨으면 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11월 1일 새벽 주문 - 연락X - 문의글 다수 올라옴 - 재고 입고 상황에 따라...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>좋아요좋아요좋아요좋아요</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>아이패드잘받았습니다생각보다 작네요</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>배송안내문자를 받을 수있었으면 더 좋았을 듯</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>아 스트레치 귀찬아서 그냥쓴다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>펜슬 같이 주문했는데 2주넘게 안옴.보낸다 보낸다 몇번이나 말해놓고 안옴.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review star\n",
       "0    4일만에 도착!!! 폭설로 택배사에서 하루 주무심!그레이 생각보다 괜찮네요!뭐 작동...    4\n",
       "1    상품은 안전하게 잘 와서 너무 만족합니다. 하자도 없고 원하던 색상으로 잘 왔어요~...    4\n",
       "2    배송 빠른건 정말 너무 만족했어요!하지만 배송 과정 중의 문제인지는 모르겠지만 아이...    4\n",
       "3    해외서 오는 시간이 있어 배송이 조금 아쉬웠지만 만족합니다. 문구에 적어 주셨으면 ...    4\n",
       "4    11월 1일 새벽 주문 - 연락X - 문의글 다수 올라옴 - 재고 입고 상황에 따라...    4\n",
       "..                                                 ...  ...\n",
       "170                                       좋아요좋아요좋아요좋아요    3\n",
       "171                                 아이패드잘받았습니다생각보다 작네요    2\n",
       "172                           배송안내문자를 받을 수있었으면 더 좋았을 듯    2\n",
       "173                                   아 스트레치 귀찬아서 그냥쓴다    1\n",
       "174          펜슬 같이 주문했는데 2주넘게 안옴.보낸다 보낸다 몇번이나 말해놓고 안옴.    1\n",
       "\n",
       "[175 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
